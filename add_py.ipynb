{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNVYPasxs8g7UnYP8sPA9MM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIQN-OAbCa1e",
        "outputId": "9a37d2d4-b77b-42d7-dd10-40b70beb67fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting add.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile add.py\n",
        "import numpy as np\n",
        "from numba import cuda\n",
        "import hashlib\n",
        "\n",
        "@cuda.jit\n",
        "def add_array(a,b,c):\n",
        "  i = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "  if (i < a.size):\n",
        "    c[i] = a[i] + b[i]\n",
        "\n",
        "N = 512\n",
        "a = np.arange(N,dtype=np.float32)\n",
        "b = np.arange(N,dtype=np.float32)\n",
        "\n",
        "#allocate a device array dev_c on the GPU using cuda.device_array_like:\n",
        "dev_a = cuda.to_device(a)\n",
        "dev_b = cuda.to_device(b)\n",
        "dev_c = cuda.device_array_like(a)\n",
        "\n",
        "add_array[512,512](dev_a,dev_b,dev_c)\n",
        "\n",
        "#copy result back\n",
        "c = dev_c.copy_to_host()\n",
        "\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python add.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTeVtwtwD8Bf",
        "outputId": "d28472ed-37c4-4c2e-91e2-64f0894def86"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   0.    2.    4.    6.    8.   10.   12.   14.   16.   18.   20.   22.\n",
            "   24.   26.   28.   30.   32.   34.   36.   38.   40.   42.   44.   46.\n",
            "   48.   50.   52.   54.   56.   58.   60.   62.   64.   66.   68.   70.\n",
            "   72.   74.   76.   78.   80.   82.   84.   86.   88.   90.   92.   94.\n",
            "   96.   98.  100.  102.  104.  106.  108.  110.  112.  114.  116.  118.\n",
            "  120.  122.  124.  126.  128.  130.  132.  134.  136.  138.  140.  142.\n",
            "  144.  146.  148.  150.  152.  154.  156.  158.  160.  162.  164.  166.\n",
            "  168.  170.  172.  174.  176.  178.  180.  182.  184.  186.  188.  190.\n",
            "  192.  194.  196.  198.  200.  202.  204.  206.  208.  210.  212.  214.\n",
            "  216.  218.  220.  222.  224.  226.  228.  230.  232.  234.  236.  238.\n",
            "  240.  242.  244.  246.  248.  250.  252.  254.  256.  258.  260.  262.\n",
            "  264.  266.  268.  270.  272.  274.  276.  278.  280.  282.  284.  286.\n",
            "  288.  290.  292.  294.  296.  298.  300.  302.  304.  306.  308.  310.\n",
            "  312.  314.  316.  318.  320.  322.  324.  326.  328.  330.  332.  334.\n",
            "  336.  338.  340.  342.  344.  346.  348.  350.  352.  354.  356.  358.\n",
            "  360.  362.  364.  366.  368.  370.  372.  374.  376.  378.  380.  382.\n",
            "  384.  386.  388.  390.  392.  394.  396.  398.  400.  402.  404.  406.\n",
            "  408.  410.  412.  414.  416.  418.  420.  422.  424.  426.  428.  430.\n",
            "  432.  434.  436.  438.  440.  442.  444.  446.  448.  450.  452.  454.\n",
            "  456.  458.  460.  462.  464.  466.  468.  470.  472.  474.  476.  478.\n",
            "  480.  482.  484.  486.  488.  490.  492.  494.  496.  498.  500.  502.\n",
            "  504.  506.  508.  510.  512.  514.  516.  518.  520.  522.  524.  526.\n",
            "  528.  530.  532.  534.  536.  538.  540.  542.  544.  546.  548.  550.\n",
            "  552.  554.  556.  558.  560.  562.  564.  566.  568.  570.  572.  574.\n",
            "  576.  578.  580.  582.  584.  586.  588.  590.  592.  594.  596.  598.\n",
            "  600.  602.  604.  606.  608.  610.  612.  614.  616.  618.  620.  622.\n",
            "  624.  626.  628.  630.  632.  634.  636.  638.  640.  642.  644.  646.\n",
            "  648.  650.  652.  654.  656.  658.  660.  662.  664.  666.  668.  670.\n",
            "  672.  674.  676.  678.  680.  682.  684.  686.  688.  690.  692.  694.\n",
            "  696.  698.  700.  702.  704.  706.  708.  710.  712.  714.  716.  718.\n",
            "  720.  722.  724.  726.  728.  730.  732.  734.  736.  738.  740.  742.\n",
            "  744.  746.  748.  750.  752.  754.  756.  758.  760.  762.  764.  766.\n",
            "  768.  770.  772.  774.  776.  778.  780.  782.  784.  786.  788.  790.\n",
            "  792.  794.  796.  798.  800.  802.  804.  806.  808.  810.  812.  814.\n",
            "  816.  818.  820.  822.  824.  826.  828.  830.  832.  834.  836.  838.\n",
            "  840.  842.  844.  846.  848.  850.  852.  854.  856.  858.  860.  862.\n",
            "  864.  866.  868.  870.  872.  874.  876.  878.  880.  882.  884.  886.\n",
            "  888.  890.  892.  894.  896.  898.  900.  902.  904.  906.  908.  910.\n",
            "  912.  914.  916.  918.  920.  922.  924.  926.  928.  930.  932.  934.\n",
            "  936.  938.  940.  942.  944.  946.  948.  950.  952.  954.  956.  958.\n",
            "  960.  962.  964.  966.  968.  970.  972.  974.  976.  978.  980.  982.\n",
            "  984.  986.  988.  990.  992.  994.  996.  998. 1000. 1002. 1004. 1006.\n",
            " 1008. 1010. 1012. 1014. 1016. 1018. 1020. 1022.]\n"
          ]
        }
      ]
    }
  ]
}